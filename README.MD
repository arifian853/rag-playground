## ðŸ“˜ RAG Parameter Exploration Assignment

Pada tugas ini kamu akan bereksperimen dengan **5 parameter utama Retrieval-Augmented Generation (RAG)** + **opsi model Groq**.

Kamu akan:

âœ… memahami efek tuning RAG
âœ… mengamati perubahan kualitas vs kecepatan
âœ… belajar trade-off retrieval & generation
âœ… menulis insight praktis dari eksperimen

> Tools sudah disediakan. Kamu **tidak perlu ngoding**, hanya ubah nilai parameter di file Python & restart server.

**Notes:** 
**- Ikuti video di LMS jika kamu kebingungan.**
**- Sediakan penyimpanan at least 2GB, bakalan ada download model yang cukup besar ke laptopmu.**
**- Hapus proyek ini kalau sudah selesai, biar laptop mu tidak tercekik**
**- Ketika proyek ini sudah diisi, sudah dikerjakan dibawah, maka upload ke GitHub.**

---

## âš™ï¸ Parameter yang diuji

### 1ï¸âƒ£ Ukuran chunk

```python
CHUNK_SIZE = 300
```

**Fungsi**
Mengatur seberapa besar potongan teks untuk embedding.

| Arah tuning               | Efek                                              |
| ------------------------- | ------------------------------------------------- |
| **Lebih besar** (400â€“600) | ? (jawab) |
| **Lebih kecil** (150â€“250) | ? (jawab) |

**Pertanyaan refleksi**

* Chunk besar atau kecil lebih tepat untuk dokumen yang kamu tes?

---

### 2ï¸âƒ£ Kandidat awal vector search

```python
TOP_K_INITIAL = 20
```

**Fungsi**
Berapa dokumen paling mirip yang diambil sebelum filtering.

| Arah tuning         | Efek                                                |
| ------------------- | --------------------------------------------------- |
| **Naikkan** (30â€“50) | ? (jawab) |
| **Turunkan** (5â€“10) | ? (jawab) |

**Pertanyaan**

* Apakah top-k kecil cukup untuk dataset kamu?

---

### 3ï¸âƒ£ Konten final ke LLM

```python
FINAL_TOP_M = 5
```

**Fungsi**
Jumlah konteks yang akhirnya dimasukkan ke prompt LLM.

| Arah tuning        | Efek                                        |
| ------------------ | ------------------------------------------- |
| **Naikkan** (6â€“8)  | ? (jawab) |
| **Turunkan** (2â€“3) | ? (jawab) |

**Pertanyaan**

* Benarkah â€œsemakin banyak konteks semakin bagusâ€?

---

### 4ï¸âƒ£ Cross-Encoder Re-ranker

```python
USE_RERANKER = True
```

**Fungsi**
Menilai ulang (rerank) dokumen hasil embedding.

| Mode    | Efek                                    |
| ------- | --------------------------------------- |
| `True`  | ? (jawab) |
| `False` | ? (jawab) |

**Pertanyaan**

* Pada query jenis apa reranker paling terasa manfaatnya?

---

### 5ï¸âƒ£ Temperatur generasi

```python
TEMPERATURE = 0.2
```

**Fungsi**
Mengontrol variasi / kreativitas jawaban.

| Value   | Efek                                  |
| ------- | ------------------------------------- |
| 0.0â€“0.2 | ? (jawab) |
| 0.5â€“0.7 | ? (jawab) |

**Pertanyaan**

* Untuk QA berbasis dokumen perusahaan, temperatur ideal berapa?

---

### 6ï¸âƒ£ Model LLM Groq

```python
GROQ_MODEL = "llama-3.1-8b-instant"
# alternatif:
# gpt-oss-120b
# llama-3.3-70b-versatile
```

| Pilihan                  | Efek                                |
| ------------------------ | ----------------------------------- |
| Model kecil (8B)         | ? (jawab) |
| Model besar (70B / 120B) | ? (jawab) |

**Pertanyaan**

* Apakah peningkatan kualitas sebanding dengan penambahan waktu?

---

> Gunakan **pertanyaan nyata** dari konten PDF yang kamu upload.

---

## Tips

* Pakai PDF minimal 1 halaman, maksimal 10 halaman, biar gak berat.
* Coba pertanyaan definisi, konteks, dan reasoning
* Catat kapan sistem salah & mengapa
* Prioritaskan kualitas hasil dalam laporan

---
