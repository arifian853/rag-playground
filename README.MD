## üìò RAG Parameter Exploration Assignment

Pada tugas ini kamu akan bereksperimen dengan **5 parameter utama Retrieval-Augmented Generation (RAG)** + **opsi model Groq**.

Kamu akan:

‚úÖ memahami efek tuning RAG

‚úÖ mengamati perubahan kualitas vs kecepatan

‚úÖ belajar trade-off retrieval & generation

‚úÖ menulis insight praktis dari eksperimen

> Tools sudah disediakan. Kamu **tidak perlu ngoding**, hanya ubah nilai parameter di file Python & restart server.

**Notes:** 

**- Ikuti video di LMS jika kamu kebingungan.**

**- Sediakan penyimpanan at least 2GB, bakalan ada download model yang cukup besar ke laptopmu.**

**- Hapus proyek ini kalau sudah selesai, biar laptop mu tidak tercekik**

**- Ketika proyek ini sudah diisi, sudah dikerjakan dibawah, maka upload ke GitHub.**

---

## ‚öôÔ∏è Parameter yang diuji

### 1Ô∏è‚É£ Ukuran chunk

```python
CHUNK_SIZE = 300
```

**Fungsi**
Mengatur seberapa besar potongan teks untuk embedding.

| Arah tuning               | Efek                                              |
| ------------------------- | ------------------------------------------------- |
| **Lebih besar** (400‚Äì600) | ? (jawab) |
| **Lebih kecil** (150‚Äì250) | ? (jawab) |

**Pertanyaan**

* Chunk besar atau kecil lebih tepat untuk dokumen yang kamu tes?
* Jawab : 

---

### 2Ô∏è‚É£ Kandidat awal vector search

```python
TOP_K_INITIAL = 20
```

**Fungsi**
Berapa dokumen paling mirip yang diambil sebelum filtering.

| Arah tuning         | Efek                                                |
| ------------------- | --------------------------------------------------- |
| **Naikkan** (30‚Äì50) | ? (jawab) |
| **Turunkan** (5‚Äì10) | ? (jawab) |

**Pertanyaan**

* Apakah top-k kecil cukup untuk dataset kamu?
* Jawab : 

---

### 3Ô∏è‚É£ Konten final ke LLM

```python
FINAL_TOP_M = 5
```

**Fungsi**
Jumlah konteks yang akhirnya dimasukkan ke prompt LLM.

| Arah tuning        | Efek                                        |
| ------------------ | ------------------------------------------- |
| **Naikkan** (6‚Äì8)  | ? (jawab) |
| **Turunkan** (2‚Äì3) | ? (jawab) |

**Pertanyaan**

* Benarkah ‚Äúsemakin banyak konteks semakin bagus‚Äù?
* Jawab : 

---

### 4Ô∏è‚É£ Cross-Encoder Re-ranker

```python
USE_RERANKER = True
```

**Fungsi**
Menilai ulang (rerank) dokumen hasil embedding.

| Mode    | Efek                                    |
| ------- | --------------------------------------- |
| `True`  | ? (jawab) |
| `False` | ? (jawab) |

**Pertanyaan**

* Pada query jenis apa reranker paling terasa manfaatnya?
* Jawab : 

---

### 5Ô∏è‚É£ Temperatur generasi

```python
TEMPERATURE = 0.2
```

**Fungsi**
Mengontrol variasi / kreativitas jawaban.

| Value   | Efek                                  |
| ------- | ------------------------------------- |
| 0.0‚Äì0.2 | ? (jawab) |
| 0.5‚Äì0.7 | ? (jawab) |

**Pertanyaan**

* Untuk QA berbasis dokumen perusahaan, temperatur ideal berapa?
* Jawab : 

---

### 6Ô∏è‚É£ Model LLM Groq

```python
GROQ_MODEL = "llama-3.1-8b-instant"
# alternatif:
# gpt-oss-120b
# llama-3.3-70b-versatile
```

| Pilihan                  | Efek                                |
| ------------------------ | ----------------------------------- |
| Model kecil (8B)         | ? (jawab) |
| Model besar (70B / 120B) | ? (jawab) |

**Pertanyaan**

* Apakah peningkatan kualitas sebanding dengan penambahan waktu?
* Jawab : 

---

## Tips

* Pakai PDF minimal 1 halaman, maksimal 10 halaman, biar gak berat.
* Coba pertanyaan definisi, konteks, dan reasoning
* Catat kapan sistem salah & mengapa
* Prioritaskan kualitas hasil dalam laporan

---
